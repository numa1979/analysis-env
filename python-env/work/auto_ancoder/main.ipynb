{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspaces/python-env/work/data/Sensor2.csv', header=None, delimiter='\\t')\n",
    "# df = pd.read_csv('/workspaces/python-env/work/data/sample_data.txt', header=None, delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecg_dataset = df.iloc[:,2].values\n",
    "# ecg_dataset = np.array(ecg_dataset)\n",
    "ecg_dataset = df.values\n",
    "ecg_dataset = ecg_dataset.reshape(len(ecg_dataset), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(ecg_dataset, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均値を0にする\n",
    "ecg_dataset_mean = ecg_dataset.mean()\n",
    "ecg_dataset = (ecg_dataset - ecg_dataset_mean)\n",
    "\n",
    "# データセットの最大値で割り、-1～1の範囲に収まるように正規化する\n",
    "ecg_dataset_max = np.abs(ecg_dataset).max()\n",
    "ecg_dataset = ecg_dataset / ecg_dataset_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとテストデータに分割\n",
    "# 0～5000をテスト用データ\n",
    "test_data = ecg_dataset[:80]\n",
    "# 5001～10000を学習用データ\n",
    "train_data = ecg_dataset[80:120]\n",
    "# train_data,test_data = train_test_split(ecg_dataset,test_size=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データプロット\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.ylim(-1, 1)\n",
    "plt.plot(train_data, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータプロット\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.ylim(-1, 1)\n",
    "plt.plot(test_data, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TIME_STEPS = 12\n",
    "\n",
    "def create_dataset(array, time_steps=TIME_STEPS):\n",
    "    dataset_list = []\n",
    "\n",
    "    for i in range(len(array) - time_steps + 1):\n",
    "        dataset_list.append(array[i : (i + time_steps)])\n",
    "\n",
    "    return np.stack(dataset_list)\n",
    "\n",
    "# 学習データセットとテストデータセットを作成\n",
    "x_train = create_dataset(train_data)\n",
    "print(\"train_data: \",train_data.shape)\n",
    "print(\"x_train: \",x_train.shape)\n",
    "\n",
    "x_test = create_dataset(test_data)\n",
    "print(\"test_data: \", test_data.shape)\n",
    "print(\"x_test: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        # 入力層\n",
    "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS, 1)),\n",
    "     \n",
    "        # エンコード層\n",
    "        tf.keras.layers.Conv1D(\n",
    "            filters=64, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Conv1D(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "       \n",
    "        # デコード層\n",
    "        tf.keras.layers.Conv1DTranspose(\n",
    "            filters=64, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Conv1DTranspose(\n",
    "            filters=64, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "    \n",
    "        # 出力層\n",
    "        tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "# モデルの構造確認\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練\n",
    "history = model.fit(\n",
    "    x=x_train,  # 学習データ\n",
    "    y=x_train,  # 教師データ(オートエンコーダの学習のため学習データをそのまま入れる)\n",
    "    validation_split=0.1,  # 検証データ比率(学習データの1割を検証データとして使用する)\n",
    "    epochs=50,  # エポック数\n",
    "    batch_size=128,  # バッチサイズ\n",
    "    callbacks=[\n",
    "        # コールバック指定\n",
    "        # 5回検証Lossの改善が無かったら学習を打ち切るよう設定\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練したモデルで推論\n",
    "temp_data = x_train[0]\n",
    "temp_data = temp_data.reshape(-1, TIME_STEPS, 1)\n",
    "\n",
    "temp_result = model.predict(temp_data)\n",
    "\n",
    "plt.plot(temp_data[0])\n",
    "plt.plot(temp_result[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_predict_result = model.predict(x_train)\n",
    "\n",
    "train_abs = np.abs(x_train_predict_result - x_train)\n",
    "train_mae = np.mean(train_abs, axis=1)\n",
    "train_mae = train_mae.reshape(-1)\n",
    "\n",
    "plt.hist(train_mae, bins=50)\n",
    "plt.xlabel(\"Train MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.max(train_mae)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_predict_result = model.predict(x_test)\n",
    "\n",
    "test_abs = np.abs(x_test_predict_result - x_test)\n",
    "test_mae = np.mean(test_abs, axis=1)\n",
    "test_mae = test_mae.reshape(-1)\n",
    "\n",
    "plt.hist(test_mae, bins=50)\n",
    "plt.xlabel(\"Test MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 異常検知したデータの数と異常検知したデータのインデックスを確認\n",
    "anomaly_result = test_mae > threshold\n",
    "\n",
    "# 異常検知個数\n",
    "print(np.sum(anomaly_result))\n",
    "\n",
    "# 異常検知したインデックス\n",
    "print(np.where(anomaly_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(test_data, color=\"b\")\n",
    "\n",
    "for index, anomaly in enumerate(anomaly_result):\n",
    "    if anomaly:\n",
    "        x = np.arange(index, index + TIME_STEPS)\n",
    "        y1 = [-1]*len(x)\n",
    "        y2 = [1]*len(x)\n",
    "        plt.fill_between(x, y1, y2, facecolor='r', alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(time_steps, num_layer, num_filters, kernel_size, strides, dropout_rate, activation):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # 入力層\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(time_steps, 1)))\n",
    "\n",
    "    # エンコード層\n",
    "    for i in range(num_layer):\n",
    "        filters = int(num_filters / (i+1))\n",
    "\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=filters, kernel_size=kernel_size, padding=\"same\", strides=strides, activation=activation\n",
    "            )\n",
    "        )\n",
    "        if i < (num_layer - 1):\n",
    "            model.add(tf.keras.layers.Dropout(rate=dropout_rate))\n",
    "\n",
    "    # デコード層\n",
    "    for i in reversed(range(num_layer)):\n",
    "        filters = int(num_filters / (i+1))\n",
    "\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv1DTranspose(\n",
    "                filters=filters, kernel_size=kernel_size, padding=\"same\", strides=strides, activation=activation\n",
    "            )\n",
    "        )\n",
    "        if i != 0:\n",
    "            model.add(tf.keras.layers.Dropout(rate=dropout_rate))\n",
    "\n",
    "    # 出力層\n",
    "    model.add(\n",
    "        tf.keras.layers.Conv1DTranspose(\n",
    "            filters=1, kernel_size=kernel_size, padding=\"same\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # レイヤー数\n",
    "    num_layer = trial.suggest_int(\"num_layer\", 1, 3)\n",
    "    # 畳み込みフィルター数\n",
    "    num_filters = int(trial.suggest_categorical(\"num_filters\", [16, 32, 64]))\n",
    "    # 畳み込みカーネルサイズ\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 5, 2)\n",
    "    # 畳み込みストライドサイズ\n",
    "    strides = trial.suggest_int(\"strides\", 2, 4, 2)\n",
    "    # ドロップアウト割合\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n",
    "    # 活性化関数\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"sigmoid\", \"tanh\"])\n",
    "    \n",
    "    # 最適化アルゴリズム\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"adam\"])\n",
    "\n",
    "    # モデル構築・コンパイル\n",
    "    model = create_model(TIME_STEPS, num_layer, num_filters, kernel_size, strides, dropout_rate, activation)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    # 訓練開始\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        x_train,\n",
    "        epochs=50,\n",
    "        batch_size=128,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return history.history[\"val_loss\"][-1]\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(study.best_params)\n",
    "\n",
    "model2 = create_model(\n",
    "    TIME_STEPS, \n",
    "    study.best_params['num_layer'], \n",
    "    study.best_params['num_filters'], \n",
    "    study.best_params['kernel_size'],\n",
    "    study.best_params['strides'], \n",
    "    study.best_params['dropout_rate'],\n",
    "    study.best_params['activation'],\n",
    ")\n",
    "\n",
    "model2.compile(optimizer=study.best_params['optimizer'], loss=\"mse\")\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "history = model2.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_predict_result2 = model2.predict(x_train)\n",
    "\n",
    "train_abs2 = np.abs(x_train_predict_result2 - x_train)\n",
    "train_mae2 = np.mean(train_abs2, axis=1)\n",
    "train_mae2 = train_mae2.reshape(-1)\n",
    "\n",
    "plt.hist(train_mae2, bins=50)\n",
    "plt.xlabel(\"Train MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold2 = np.max(train_mae2)\n",
    "print(threshold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_predict_result2 = model2.predict(x_test)\n",
    "\n",
    "test_abs2 = np.abs(x_test_predict_result2 - x_test)\n",
    "test_mae2 = np.mean(test_abs2, axis=1)\n",
    "test_mae2 = test_mae2.reshape(-1)\n",
    "\n",
    "plt.hist(test_mae2, bins=50)\n",
    "plt.xlabel(\"Test MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_result2 = test_mae2 > threshold2\n",
    "print(np.sum(anomaly_result2))\n",
    "print(np.where(anomaly_result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "plt.plot(test_data, color=\"b\")\n",
    "\n",
    "for index, anomaly in enumerate(anomaly_result2):\n",
    "    if anomaly:\n",
    "        x = np.arange(index, index + TIME_STEPS)\n",
    "        y1 = [-1]*len(x)\n",
    "        y2 = [1]*len(x)\n",
    "        plt.fill_between(x, y1, y2, facecolor='r', alpha=.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
